So, you learned about graph theory in school? No? Well strap in. Yes? Well, strap in anyways.

So, Königsberg (before it was renamed Kaliningrad) had some bridges. Some guy named Euler who you might have heard of was wondering if you can walk across every single bridge, but only once.

And, to solve this mildly interesting riddle, the answer's no btw, he invented the entire field of graph theory. Or just started it, idk.


So, now let's circle back to programming.
A graph can be represented by 2 things: vertices and edges[^1].
A vertex represents a point, an edge represents a link between 2 vertices.

An edge might have a direction, if it does it points from one vertex to another.
If we have the edge (A,B), but not (B,A), we say that B is adjacent to A, but not the other way around.
If we're in a non-directed graph, the edge (A,B) means A and B are adjacent.

As a small aside, and non-directed graph can be represented by a directed graph, with every edge instead being 2 edges, one going A to B, and the other B to A.

A graph may be pondered, if it's got a weight assigned to it's edges.

Lastly, graphs can be separated into 2 categories, multigraphs, and simple graphs.

Multigraphs are more complex, they can have multiple edges between the same vertices, and edges linking a vertex to itself. 
Simple graphs can't.

## Use cases

Graphs have lots of uses.

A simple and obvious one is a road network.
Another would be a railway network. Call SBB's IT department if you want to learn more.

Probably the best use case, and this is why everyone in programming has heard of graphs, is because of social media. They are used on every social media, from Facebook to Youtube to \[insert whatever you use here\].

## Putting graphs in computer

There's a lot of ways to store a graph in a computer.

The two most common ways to do it include:
- adjacency matrices
- adjacency lists

We're going to from now on be considering a graph G, with n vertices.

If G s directed, m, the number of edges, can have any value between 0 and n(n-1), if it isn't between 0 and n(n-1)/2.


To represent G with an adjacency matrix, the matrix will be an n by n matrix (n being number of vertices). If at the coordinates u,v we have 0, you don't have an edge from u to v. If it's 1, you have one.

What's nice is that if the matrix is not directed, it's symmetrical, if it's directed, it isn't.

If G is pondered, it's possible to replace 1 with the weight (this doesn't always work, it's possible that you might have a weight of 0. But if that's not a risk, that's quite good).


To represent G with an adjacency list, you counter-intuitively need a dictionary.

What we do is we have `{0:[1],1:[2,3],2[3],3[2]}`. The way is works is that the dictionary stores a list of where the node[^2] links to.

It's quite nice, but has issues as well.

### What's the best way to store them

Well, first let's talk a bit more about python's data structures.

Well, the thing is that at least in python, lists are stored in an interesting way.
Lists store pointers to the actual data located somewhere™.
This allows lists to have cells all of the same size, because to get the *i*th element, we just need to take i times the size of a pointer, add that to where the list starts in memory. 
This allows to get elements from it in O(1) time.

This has several issues, notably with stuff like insert, remove, pop(i), or del, we need to move every element afterwards.

Dictionaries in python are quicker, but we won't talk about it too much, because it's more complex.

Essentially, blah blah blah, we hash the keys (turn them into unique values that the computer knows how to read real fast) blah blah assign stuff to them fast because no reordering blah blah remove as well blah blah.


in other terms, the adjacency matrix always takes up n2 space, while the adjacency list 'only'  has up to n2 space.

The adjacency list is however much faster when adding nodes, when we need to find every element adjacent, leaving it at effectively $\Theta(1)$.
It loses when checking if a node has a connection with another one however, as matrices can do that in constant time.

## Paths and distance

A path of length l between u and v is a list of vertices, with a length of greater than 1, all of them distinct, which link between u and v.
The shortest path is the one for which l is lowest.
The distance is the length between these 2 points.
We also say if there's a path that v is attainable from u.

In directed graph, distance isn't necessarily symmetrical. 

## Finally, some algorithms

Ok, so we need to find a way, starting at a node, to get to every single node.

Two algorithms we have are Breath-First-Search, and Depth-First-Search.
I'd explain the differences, but I don't think you care about them, and also I don't have the time, look at the moodle.

We'll quickly implement BFS here.
It's going to be a bit flawed, but it's good enough.

```python
G1 = {0: [1, 2, 3], 1: [0, 2], 2: [0, 1, 4],
	3: [0], 4: [2, 5, 6], 5: [4, 6], 6: [4, 5]}

def BFS(G: dict, s: int):
	# is the graph, s the stating point.
	to_traverse = [s]
	seen = {u: False for u in G.keys()}
	seen[s] = True

	while to_traverse: # will run until to_traverse is empty
		vertex = to_traverse.pop(0)
		for v in G[vertex]:
			if not seen[v]:
				to_traverse.append(v)
				seen[v] = True
		print(vertex)

BFS(G1, 1)
```


[[6. Sorting Algorithms|Previous]]

[^1]:Linguistic drift is not doing this field justice

[^2]: Used here as a synonym for vertex
